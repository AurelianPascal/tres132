// Import necessary libraries
import org.apache.spark.sql.functions._

// Define the path to your Delta Lake table and other constants
val deltaPath = "dbfs:/path/to/your/delta/table"
val lastReconciliationTime = "2023-01-01T00:00:00"

// Dummy SQL Server connection details
val serverName = "your_server.database.windows.net"
val databaseName = "your_database_name"
val user = "your_username"
val password = "your_password"
val dbTable = "events"
val discrepancyTable = "reconciliation_discrepancies"

val readOptions = Map(
  "url" -> s"jdbc:sqlserver://$serverName;databaseName=$databaseName",
  "dbtable" -> dbTable,
  "user" -> user,
  "password" -> password,
  "partitionColumn" -> "id", // Adjust as needed
  "lowerBound" -> "1",
  "upperBound" -> "10000",
  "numPartitions" -> "4"
)

val writeOptions = Map(
  "url" -> s"jdbc:sqlserver://$serverName;databaseName=$databaseName",
  "dbtable" -> discrepancyTable,
  "user" -> user,
  "password" -> password
)

// Function to load data from Delta Lake
def loadDeltaData(deltaPath: String, lastReconciliationTime: String): DataFrame = {
  spark.read.format("delta").load(deltaPath)
    .select("id", "event_version", "last_updated_time")
    .filter(s"last_updated_time >= '$lastReconciliationTime'")
}

// Function to load data from SQL Server
def loadSqlData(readOptions: Map[String, String], lastReconciliationTime: String): DataFrame = {
  spark.read.format("com.microsoft.sqlserver.jdbc.spark")
    .options(readOptions)
    .load()
    .select("id", "event_version", "last_updated_time")
    .filter(s"last_updated_time >= '$lastReconciliationTime'")
}

// Function to write data to SQL Server
def writeDataToSql(df: DataFrame, writeOptions: Map[String, String]): Unit = {
  df.write.format("com.microsoft.sqlserver.jdbc.spark").options(writeOptions).mode("append").save()
}

// Function to identify and write discrepancies
def identifyAndWriteDiscrepancies(deltaDf: DataFrame, sqlDf: DataFrame, writeOptions: Map[String, String]): Unit = {
  val diffsToSave = deltaDf.join(sqlDf, Seq("id", "event_version"), "full_outer")
    .where(deltaDf("id").isNull || sqlDf("id").isNull)
    .select(deltaDf("id"), deltaDf("event_version"), lit("example_datatype").as("datatype"))
    .withColumn("created_at", current_timestamp())

  writeDataToSql(diffsToSave, writeOptions)
}

// Load data from Delta Lake and SQL Server
val deltaDf = loadDeltaData(deltaPath, lastReconciliationTime)
val sqlDf = loadSqlData(readOptions, lastReconciliationTime)

// Identify discrepancies and write them to SQL Server
identifyAndWriteDiscrepancies(deltaDf, sqlDf, writeOptions)

println("Differences saved successfully to SQL Server.")
